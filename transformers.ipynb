{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sveta\\projects\\astro-main\\text_venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
      "     ------------------------------------ 362.3/362.3 kB 317.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: transformers[sentencepiece] in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (4.21.0.dev0)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "     ------------------------------------ 140.6/140.6 kB 595.3 kB/s eta 0:00:00\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-8.0.0-cp310-cp310-win_amd64.whl (17.9 MB)\n",
      "     ---------------------------------------- 17.9/17.9 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from datasets) (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from datasets) (1.22.4)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n",
      "     ------------------------------------ 133.1/133.1 kB 982.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from datasets) (2.28.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from datasets) (1.4.2)\n",
      "Collecting dill<0.3.6\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.8/95.8 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp310-cp310-win_amd64.whl (555 kB)\n",
      "     -------------------------------------- 555.1/555.1 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from transformers[sentencepiece]) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from transformers[sentencepiece]) (3.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from transformers[sentencepiece]) (2022.6.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from transformers[sentencepiece]) (0.12.1)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91\n",
      "  Using cached sentencepiece-0.1.96-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from transformers[sentencepiece]) (3.19.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.5)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp310-cp310-win_amd64.whl (27 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp310-cp310-win_amd64.whl (122 kB)\n",
      "     -------------------------------------- 122.2/122.2 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sveta\\projects\\astro-main\\text_venv\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: sentencepiece, xxhash, pyarrow, multidict, fsspec, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 datasets-2.3.2 dill-0.3.5.1 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 multiprocess-0.70.13 pyarrow-8.0.0 responses-0.18.0 sentencepiece-0.1.96 xxhash-3.0.0 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!py -m pip install datasets transformers[sentencepiece]\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n",
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 223kB/s]\n",
      "Downloading: 100%|██████████| 475M/475M [07:18<00:00, 1.14MB/s]    \n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Downloading: 100%|██████████| 0.99M/0.99M [00:00<00:00, 1.24MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 600kB/s] \n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:03<00:00, 430kB/s] \n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Девам обещаютш в ідет Вом мнодоверик.\\n\\nIn case of Russian war'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"Девам обещают\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 762/762 [00:00<?, ?B/s] \n",
      "Downloading: 100%|██████████| 313M/313M [05:59<00:00, 911kB/s]  \n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Downloading: 100%|██████████| 0.99M/0.99M [00:03<00:00, 302kB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:01<00:00, 277kB/s] \n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:03<00:00, 374kB/s] \n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Девам обещают дис погноваю and I was working, so I\\u202cm thinking that I really am now.\\u202c'},\n",
       " {'generated_text': 'Девам обещаютел беравож Сожий, на десторуский солий наи в «беруская, n. e. чещаютел обеща�'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"Девам обещают\",\n",
    "    max_length=100,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Девам обещаютенорения, Тлбождра\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'},\n",
       " {'generated_text': 'Девам обещают приднуй возно вознов середногонестьно. Намигий пприднуй в поздернов вамого. Нигий пприднуй в поздернов сероредногонестьно. Намигий пприднуй в поздернов в поздернов в бещают приднуй в поздернов в мегий в поздернов в обещают приднестьно. Намигий приднуй в поздернов в поздернов в поздернов в обещают приднуй в ют приднуй в поздернов общают приднуй в поздернов обещают приднуй в поздернов обещают приднуй в поздернов обещают приднуй в ют приднуй в поздернов обещают приднуй в поздернов обещают приднуй в поздернов обещают приднуй в поздернов обещают приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй в ют приднуй'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\n",
    "    \"Девам обещают\",\n",
    "    max_length=1000,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гороскоп - это бессмыслица\n",
    "Ничего страшного, если гороскоп не имеет никакого смысла. Мы тренировались всего на паре мегабайтов текста. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...to be continued..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('text_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "390155150943988f0db8c0455a322502215b53d84351eec9c2e5243e3918bb94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
